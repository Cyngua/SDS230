---
title: "Class 24 notes and code"
output:
  pdf_document: default
  html_document: default
---





$\\$



<!--  Please run the code in the  R chunk below once. This will install some packages and download data and images needed for these exercises.  -->

```{r message=FALSE, warning = FALSE, echo = FALSE, eval = FALSE}

# makes sure you have all the packages we have used in class installed
# SDS230::update_installed_packages()

SDS230::download_data("downloading.csv")

SDS230::download_data("IPED_salaries_2016.rda")

# SDS230::download_data("Interactions_Categorical.csv")


```




```{r setup, include=FALSE}

# install.packages("latex2exp")

library(latex2exp)
library(dplyr)
library(ggplot2)

#options(scipen=999)


knitr::opts_chunk$set(echo = TRUE)

set.seed(123)

```



$\\$




## Overview


 * One-way ANOVA, Kruskal-Wallis test, and pairwise
 * 2-way ANOVA 
 * Factorial ANOVA with unbalanced designs





$\\$






## Part 1: One-way ANOVA to analyze if the time of the day affects download speeds


A college sophomore was interested in knowing whether the time of day affected the speed at which he could download files from the Internet. To address this question, he placed a file on a remote server and then proceeded to download it at three different time periods of the day: 7AM,  5PM,  12AM. He downloaded the file 48 times in all, 16 times at each time of day, and recorded the time in seconds that the download took. 

Let's assess whether the mean download time differs depending on the time of the day!





$\\$






### Part 1.1: State the null and alternative hypotheses 


Let's start as always by stating the null and alternative hypotheses:







$\\$





### Part 1.2: Run a hypothesis test using the linear regression


Let's use linear regression (i.e., the `lm()` function) to run our ANOVA comparing the download times at each time of day. 


```{r download_anova}


# get the data
download_speeds <- read.csv('downloading.csv', header = TRUE)


# running an ANOVA using the aov() and summary() functions




# we can use regression diagnostic plots to assess if ANOVA conditions have been met







# can also the lm() function to get the same results





```



$\\$






###  Part 1.3 Kruskal–Wallis test to see if any of our groups stochastically dominate another group. 

If we are concerned that our one-way ANOVA conditions are not met, we can run a Kruskal–Wallis test which does not rely on the assumptions of normality and homoscedasticity (we could also run a permutation test which does not rely on these assumptions either). 


```{r}

#Kruskal–Wallis test







```





$\\$







###  Part 1.4 Pairwise comparisons in R

If we run a one-way ANOVA and the results are statistically significant, there are a number of tests we can run to see which pairs of results are significantly different. 



```{r}


# test with no multiple comparisons adjustment (not great)





# with the Bonferroni correction





# Tukey's HSD test using the TukeyHSD() function 






```






$\\$








## Part 2: Two-way ANOVA 


Let's use a two-way ANOVA to examine if ants are more attracted to particular types of sandwiches! This is a balanced design because there are the same number of observations at each factor level combination (in this case there are 4 observations at each factor combination level).





$\\$






### Part 2.1.: Visualizing the data


Let's start by visualizing the data (you can practice stating the null and alternative hypotheses on the homework).



```{r}

# install.packages("Stat2Data")

library(Stat2Data)

data(SandwichAnts)


# visualize the data




# Two-way interaction plot using base R






```






$\\$







### Part 2.2.: Fitting the model


Let's now use a two-way ANOVA to run a hypothesis test to see if the differences are statistically significant.


```{r}


# Create a main effects only model




# Order doesn't matter for a balanced design




# Could look at diagnostic plots




```




$\\$







## Part 3: Examening unbalanced data


In an unbalanced data, there are different numbers of measured responses at the different variable levels. When running an ANOVA on unbalanced data, one needs to be careful because there are different ways to calculate the sum of squares for the different factors, and this can lead to different results about which factors are statistically significant. Let's examine this using the IPED faculty salary data. 


```{r}

load("IPED_salaries_2016.rda")

# Factor A: lecturer, assistant, associate, full professor
# Factor B: liberal arts vs research university 

IPED_3 <- IPED_salaries %>%
  filter(rank_name %in% c("Lecturer", "Assistant", "Associate", "Full")) %>%
  mutate(rank_name  = droplevels(rank_name)) %>%
  filter(CARNEGIE %in% c(15, 31)) %>%
 # na.omit() %>%
  mutate(Inst_type = dplyr::recode(CARNEGIE, "31" = "Liberal arts", "15" = "Research extensive"))


# examine properties of the data 
table(IPED_3$Inst_type, IPED_3$rank_name)


```






$\\$






### Part 3.1.: Type I sum of squares

In type I sum of squares, the sum of squares are calculated sequentially, where first SSA is taken into account, and then SSB is consider. In particular: 

* Factor A sum of squares is: SS(A) from fitting lm(y ~ A)
* Factor B sum of squares is: SS(B|A) from fitting lm(y ~ A + B) and subtracting this from SS(A)
* The interaction AB sum of squares is: SS(A, B, AB) - SS(A, B); i.e., the model is fit will lm(y ~ A*B) and then SS(A, B) is subtracted. 


```{r}

# Create a main effects and interaction model







```






$\\$






### Part 3.2.: Type III sum of squares


In type III sum of squares, the sum of squares the full model is fit SS(A, B, AB) and then the sum of squares for each factor is determined by taking the full model SS(A, B, AB) and subtracting out the fit when a given factor is missing.

* Factor A sum of squares is: SS(A, B, AB) - SS(B, AB)
* Factor B sum of squares is: SS(A, B, AB) - SS(A, AB)
* The interaction AB sum of squares is: SS(A, B, AB) - SS(A, B)


```{r}

# type III sum of squares the order that variables are added does not matter






```





$\\$





