---
title: "Class 23 notes and code"
output:
  pdf_document: default
  html_document: default
---





$\\$



<!--  Please run the code in the  R chunk below once. This will install some packages and download data and images needed for these exercises.  -->

```{r message=FALSE, warning = FALSE, echo = FALSE, eval = FALSE}

# makes sure you have all the packages we have used in class installed
SDS230::update_installed_packages()

SDS230::download_data("downloading.csv")

SDS230::download_data("IPED_salaries_2016.rda")


```




```{r setup, include=FALSE}

# install.packages("latex2exp")

library(latex2exp)
library(dplyr)
library(ggplot2)

#options(scipen=999)


knitr::opts_chunk$set(echo = TRUE)

set.seed(123)

```



$\\$




## Overview

 * One-way ANOVA
 * Connections between ANOVA and linear regression
 * 2-way ANOVA



$\\$






## Part 1: One-way ANOVA to analyze if the time of the day affects download speeds


A college sophomore was interested in knowing whether the time of day affected the speed at which he could download files from the Internet. To address this question, he placed a file on a remote server and then proceeded to download it at three different time periods of the day: 7AM,  5PM,  12AM. He downloaded the file 48 times in all, 16 times at each time of day, and recorded the time in seconds that the download took. 

Let's assess whether the mean download time differs depending on the time of the day!



$\\$





##### Part 1.1: State the null and alternative hypotheses 


Let's start as always by stating the null and alternative hypotheses:

$H_0: \mu_{7am} = \mu_{5pm} = \mu_{12am}$
$H_A: \mu_{i} \ne \mu_{j}$ for some pair of i, j


$\alpha = 0.05$




$\\$





##### Part 1.2a: Plot the data


```{r download_plot}


# get the data
download_speeds <- read.csv('downloading.csv', header = TRUE)


# create a boxplot of the data using ggplot
download_speeds %>%
  ggplot(aes(Time_of_Day, Time_Sec, fill = Time_of_Day)) + 
  geom_boxplot() + 
  xlab("Time of Day") + 
  ylab("Download speed (sec)")


```




```{r}

download_summary <- download_speeds %>%
  group_by(Time_of_Day) %>%
  summarize(SD_Time_Sec = sd(Time_Sec), 
            Time_Sec = mean(Time_Sec),
            .groups = "drop")


download_summary


download_speeds %>%
  ggplot(aes(Time_of_Day, Time_Sec, col = Time_of_Day)) + 
  geom_jitter(position = position_jitter(width = .2)) + 
  xlab("Time of Day") + 
  ylab("Download speed (sec)") + 
  geom_crossbar(download_summary, mapping = aes(ymin = Time_Sec, ymax = Time_Sec, col = Time_of_Day), size=.5,width = .5)


```





$\\$







##### Part 1.2b: Calculate the observed statistic

Our observed statistic is an F-statistic:

$F = \frac{\frac{1}{K-1}\sum_{i=1}^K n_i(\bar{x}_i - \bar{x}_{tot})^2}{\frac{1}{N-K}\sum_{i=1}^K \sum_{j=1}^{n_i} (x_{ij} - \bar{x}_i)^2}$


We will cheat and used a function I wrote above to get this F-statistic. On the homework you will need to calculate this statistic from the data using dplyr!


```{r download_obs_stat}


# Getting the observed F-statistic for the download data using built in R functions
# On the homework be sure to use dplyr to actually calculate this statistic!

(obs_stat <- anova(lm(Time_Sec~ Time_of_Day, data = download_speeds))$F[1])


  
```






$\\$






##### Step 3: Create the null distribution


Let's visualize the null distribution.


```{r download_null_dist, message = FALSE}

N <- nrow(download_speeds)
K <- 3

(df1 <- K - 1)
(df2 <- N - K)

x <- seq(-.5, 5, by = 0.01)
y <- df(x, df1, df2)

plot(x, y, type = "l")



```




$\\$




##### Part 1.4: Calculate a p-value


```{r download_pvalue}


# calculate the p-value
(p_value <- pf(obs_stat, df1, df2, lower.tail = FALSE))


```





$\\$






##### Step 1.5: Make a decision


Since `r p_value` is less than $\alpha = 0.05$ we can reject the null hypothesis, although we should really check the model assumptions before making this claim. We will do this next...






$\\$









## Part 2: Connections between ANOVA and regression 


Let's look at connections between the least squares fit we used when fitting linear regression models and our one-way ANOVA. 



$\\$



##### Step 2.1: Least squares offsets are the group means


Let's look at the mean download times for each time of day and compare it to the least squares offsets that the `lm()` function finds. 


```{r}

# get the mean and sd of the download times for each time of day
download_stats <- download_speeds %>%
  group_by(Time_of_Day) %>%
  summarize(mean_download_times = mean(Time_Sec),
            sd_download_times = sd(Time_Sec))


# fit a linear model 
fit_download <- lm(Time_Sec ~ Time_of_Day, data = download_speeds)



# check that the least squares fit offsets are the means of each group
(summary_download <- summary(fit_download))

fit_coefs <- coef(fit_download)


c(fit_coefs[1], fit_coefs[1] + fit_coefs[2], fit_coefs[1] + fit_coefs[3])

download_stats$mean_download_times

```



$\\$




##### Step 2.2: Using R to get an ANOVA table and look at diagnostic plots


We can use the `anova()` function to create an ANOVA table and we cause use the `plot()` function to look at diagnostic plots to make sure our ANOVA conditions have been met. 



```{r}

# an easy way to get the ANOVA table using the ANOVA function 
anova(fit_download)

# we can use regression diagnostic plots to assess if ANOVA conditions have been met
par(mfrow = c(2, 2))
plot(fit_download)


# we should also check that the maximum and minimum standard deviations are not greater 
# than a factor of 2 apart
print("sds")
download_stats$sd_download_times
max(download_stats$sd_download_times)/min(download_stats$sd_download_times)

```






$\\$





## Part 3: Two-way ANOVA 


Let's use a two-way ANOVA to examine if faculty salaries differ depending on:

 * The faculty rank: Full, Associate, Assistant, Lecturer
 * The type of institution: Extensive research institution vs. liberal arts college


The code filters the data to get it in to the shape we need it for the next analyses.


```{r}


load("IPED_salaries_2016.rda")

# Factor A: lecturer, assistant, associate, full professor
# Factor B: liberal arts vs research university 

IPED_3 <- IPED_salaries %>%
  filter(rank_name %in% c("Lecturer", "Assistant", "Associate", "Full")) %>%
  mutate(rank_name  = droplevels(rank_name)) %>%
  filter(CARNEGIE %in% c(15, 31)) %>%
  mutate(Inst_type = recode(CARNEGIE, "31" = "Liberal arts", "15" = "Research extensive"))


# examine properties of the data 
table(IPED_3$Inst_type, IPED_3$rank_name)



```




$\\$



#### Part 3.1: Visualizing the data


Let's start by visualizing the data.  Does there appear to be a difference in salaries for faculty rank and institution type? 


```{r}


IPED_3  %>%
  ggplot(aes(x = rank_name, y = salary_tot, col = Inst_type)) + 
  geom_jitter(alpha = .25) + 
  geom_boxplot() + 
  xlab("Faculty rank") + 
  ylab("Salary ($)") + 
  ggtitle("Salaries based on faculty rank and institution type") + 
  labs(col = "Institution type")
  

```




$\\$



#### Part 3.2.: Two-way ANOVA


Let's now use a two-way ANOVA to run a hypothesis test to see if the differences are statistically significant.


```{r}


# Create a main effects only model




```




$\\$





#### Part 3.3.: Interaction effects

We can also examine whether there is an interaction between rank and institution type. This is assessing whether the difference between faculty ranks is the same across the types of institutions or whether the differences vary depending on institution (it is similar to using the same slope or different slopes model for an interaction between a quantitative and categorical variable). 

It is useful to visualize interactions first which we can do using the interaction.plot function.


```{r}


# Two-way interaction plot using base R
interaction.plot(x.factor = IPED_3$rank_name, trace.factor = IPED_3$Inst_type, 
                 response = IPED_3$salary_tot, fun = mean, 
                 type = "b", legend = TRUE, 
                 xlab = "Rank", ylab="Salary ($)",
                 pch=c(1,19), col = c("#00AFBB", "#E7B800"))



```




$\\$





#### Part 3.4.: Testing interactions effects

Let's run an ANOVA to test if the main effects and interaction are statistically significant.



```{r}

# Create a main effects and interaction model



```





$\\$





#### Part 3.5.: Checking ANOVA assumptions


As we have discussed before, particular assumptions should be met for inferences to be valid when using ANOVAs. While ANOVAs are often robust to violations of these assumptions, one should always check them. These assumptions include that the errors (as assessed through the residuals) are normally distributed and that the variance is the same for each group. 



```{r}

par(mfrow = c(2, 2))

# plot(interaction_fit)


salary_summary <- IPED_3 %>%
  group_by(Inst_type, rank_name) %>%
  summarize(var = var(salary_tot),
            sd  = sd(salary_tot), 
            mean = mean(salary_tot), .groups = "drop")



max(salary_summary$sd)/min(salary_summary$sd)


```