---
title: "Class 23 notes and code"
output:
  pdf_document: default
  html_document: default
---





$\\$



<!--  Please run the code in the  R chunk below once. This will install some packages and download data and images needed for these exercises.  -->

```{r message=FALSE, warning = FALSE, echo = FALSE, eval = FALSE}

# makes sure you have all the packages we have used in class installed
#SDS230::update_installed_packages()

# SDS230::download_data("downloading.csv")


SDS230::download_data("IPED_salaries_2016.rda")


```




```{r setup, include=FALSE}

# install.packages("latex2exp")

library(latex2exp)
library(dplyr)
library(ggplot2)

#options(scipen=999)


knitr::opts_chunk$set(echo = TRUE)

set.seed(123)

```



$\\$




## Overview

 * One-way ANOVA
 * Connections between ANOVA and linear regression
 * Pairwise comparisons after running an ANOVA



$\\$






## Part 1: One-way ANOVA 


Let's run a one-way ANOVA to see if there is a difference in how much faculty of different ranks get paid. 




$\\$





### Part 1.1: State the null and alternative hypotheses 


Let's start as always by stating the null and alternative hypotheses:






$\\$





### Part 1.2a: Plot the data


```{r download_plot}

# get the data
load("IPED_salaries_2016.rda")



# get assistant and full professor salaries 




# create a boxplot of the data using ggplot





```




```{r}

# get a summary of the means of each group





# plot the data another way






```





$\\$







### Part 1.2b: Calculate the observed statistic

Our observed statistic is an F-statistic:

$F = \frac{\frac{1}{K-1}\sum_{i=1}^K n_i(\bar{x}_i - \bar{x}_{tot})^2}{\frac{1}{N-K}\sum_{i=1}^K \sum_{j=1}^{n_i} (x_{ij} - \bar{x}_i)^2}$


We will cheat and use the `lm()` and `anova()` functions to get the F-statistic. On the homework you will need to calculate this statistic from the data using dplyr!


```{r download_obs_stat}


# Getting the observed F-statistic for the faculty rank data using built in R functions
# On the homework be sure to use dplyr to actually calculate this statistic!





  
```






$\\$






### Step 3: Create the null distribution


Let's visualize the null distribution.


```{r download_null_dist, message = FALSE}







```




$\\$




### Part 1.4: Calculate a p-value


```{r download_pvalue}


# calculate the p-value





```





$\\$






### Step 1.5: Make a decision







$\\$









## Part 2: Connections between ANOVA and regression 


Let's look at connections between the least squares fit we used when fitting linear regression models and our one-way ANOVA. 




$\\$






### Step 2.1: Least squares offsets are the group means


Let's look at the mean download times for each time of day and compare it to the least squares offsets that the `lm()` function finds. 


```{r}

# get the mean and sd of the download times for each time of day




# fit a linear model 




# check that the least squares fit offsets are the means of each group







```



$\\$




### Step 2.2: Using R to get an ANOVA table and to look at diagnostic plots


We can use the `anova()` function to create an ANOVA table, and we can use the `plot()` function to look at diagnostic plots to make sure our ANOVA conditions have been met. 



```{r}

# an easy way to get the ANOVA table using the ANOVA function 





# we can see that the SST = SSG + SSE




# we can use regression diagnostic plots to assess if ANOVA conditions have been met




# we should also check that the maximum and minimum standard deviations are not greater 
# than a factor of 2 apart




```




$\\$






###  Part 2.3 Kruskal–Wallis test to see if any of our groups stochastically dominate another group. 

If we are concerned that our one-way ANOVA conditions are not met, we can run a Kruskal–Wallis test which does not rely on the assumptions of normality and homoscedasticity. We could also run a permutation test which does not rely on these assumptions either.


```{r}

#Kruskal–Wallis test



# compare to the ANOVA 
# anova(fit_prof)


```





$\\$






## Part 3: Pairwise comparisons after running a one-way ANOVA





###  Part 3.1 Pairwise comparisons in R

If we run a one-way ANOVA and the results are statistically significant, there are a number of tests we can run to see which pairs of results are significantly different. 



```{r}


# test with no multiple comparisons adjustment (not great)





# with the Bonferroni correction





# Note, the Bonferroni p-values are 3 times larger than the p-values with no adjustment





# Tukey's HSD test using the TukeyHSD() function 






```






$\\$













