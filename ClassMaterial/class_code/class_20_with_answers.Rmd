---
title: "Class 20 notes and code"
output:
  pdf_document: default
  html_document: default
---





$\\$




<!--  Please run the code in the  R chunk below once. This will install some
packages and download data and images needed for these exercises.  -->

```{r message=FALSE, warning = FALSE, echo = FALSE, eval = FALSE}

# makes sure you have all the packages we have used in class installed
#SDS230::update_installed_packages()

SDS230::download_data("IPED_salaries_2016.rda")



```




```{r setup, include=FALSE}

# install.packages("latex2exp")

library(latex2exp)
library(dplyr)
library(ggplot2)

#options(scipen=999)


knitr::opts_chunk$set(echo = TRUE)

set.seed(123)

```



$\\$




## Overview

 * Review of polynomial regression
 * Comparing models with R^2, adjusted R^2, AIC and BIC
 * Cross-validation
 * Visualizing multiple regression models with ggplot



$\\$





## Part 1: Review of polynomial regression


Last class we discussed polynomial regression where we created a model of the
form $y = \hat{\beta}_0 + \hat{\beta}_1 \cdot x + \hat{\beta}_2 \cdot x^2 + ...+ \hat{\beta}_k \cdot + x^k$. 
Let's explore polynomial regression a little bit more now.
 



$\\$





## Part 1.1: Comparing raw and orthogonal polynomials

As we discussed in class, by default the `poly()` function creates higher order
polynomial terms that are *orthogonal* to each other. To better understand what
*orthogonal* means you will need to take a class on linear algebra, but for our
purposes, we can see that using orthogonal polynomials reduces multicolinearity.

To explore this, let's create a synthetic data set where we will generate 1000 y
values from a third degree polynomial function of x. In particular, we will use
the equation: $y = 2x -3x^2 + 5x^3 + \epsilon$, where $\epsilon \sim ~ N(0,20)$, 
We can then fit a 6 degree polynomial model to this data and see how well
using regular or orthogonal polynomial linear regression models leads to
identifying terms of all degrees that are in the real relationship between x and y.


```{r}

set.seed(100)

# generate a synethetic data set
x <- rnorm(1000)
y <- 2*x - 3*x^2 + 5*x^3 + 20 * rnorm(1000)
plot(x, y)


# fit without orthogonal polynomials (raw = TRUE)
raw_mod <- lm(y ~ poly(x, 6, raw=TRUE))
orthogonal_mod <- lm(y ~ poly(x, 6))

# fit using orthogonal polynomials (raw = FALSE)
summary(raw_mod)
summary(orthogonal_mod)


```

Questions:
- Does the coefficient of determination $R^2$ differ when using orthogonal vs. raw polynomials? 
- Does one model better identify which terms are in the real x, y relationship? 





$\\$






## Part 1.2: Writing a function to compare R^2 statistics for different degree polynomial models


Let's now evaluate how well using polynomial models of different degrees fit the
assistant professor faculty salary data. As we discussed in class, the $R^2$
statistic (coefficient of determination) tells us the proportion of variability
in y that is explained by our model. To to assess how "good" a model is, we will
fit polynomial models of different degrees and see how this affects our $R^2$
statistic.

To make it easier repeat the process of fitting different degree polynomial
models to the faculty salary data, let's write a function called `poly_fit_r2()`
that will:

a. take as an input argument `degree` that is the degree of a polynomial
b. will fit a polynomial model of based on the degree given using raw polynomials
c. will return the $R^2$ statistic


Then let's use this function to compare $R^2$ statistic for different degree fits.


```{r}

# get the assistant professor data
load("IPED_salaries_2016.rda")
assistant_data <- filter(IPED_salaries,  endowment > 0,  rank_name == "Assistant")  



# write a function that will fit a polynomial of a given degree and return the R^2 statistic
poly_fit_r2 <- function(degree) {
  
  poly_fit <- lm(salary_tot ~ poly(log(endowment), degree, raw = TRUE),  data = assistant_data)
  
  model_summary <- summary(poly_fit)
  
  model_summary$r.squared
  
}



# assess the R^2 statistic for different degree models 
poly_fit_r2(3)

poly_fit_r2(10)
poly_fit_r2(20)

poly_fit_r2(200)



```


Which degree model has the highest $R^2$ statistic value? 






$\\$






## Part 1.3: Writing a function to visualize different degree models

Let's extend our function to take an additional Boolean argument called
`plot_model` that when set to `TRUE` will create a scatter plot of the data and
also plot the polynomial fit model as a red line.

Once we have created this function let's visualize polynomial fits of different
degrees.



```{r}


poly_fit_r2 <- function(degree, plot_model = TRUE) {
  
  poly_fit <- lm(salary_tot ~ poly(log(endowment), degree, raw = TRUE),  data = assistant_data)
  
  model_summary <- summary(poly_fit)
  
  
  if (plot_model == TRUE) {
    
    predict_df <- data.frame(endowment = 10^(seq(0, 11, by = .1)))
    
    plot(log(assistant_data$endowment), assistant_data$salary_tot, main = paste("Degree", degree))
    
    points(log(predict_df$endowment), predict(poly_fit, newdata = predict_df), type = "l", col = "red")
  
  }
  
  
  model_summary$r.squared
  
  
}


# visual polynomial fits of different degrees
poly_fit_r2(3)
poly_fit_r2(100)



#for (i in 1:100)  {
#  poly_fit_r2(i)
#  Sys.sleep(.5)
#}



```


$\\$



What would Michael Jackson say about this?  

https://www.youtube.com/watch?v=DQWI1kvmwRg






$\\$






## Part 2:  Comparing models with R^2, adjusted R^2, AIC, BIC and cross-validation


We can compare models using several statistics including $R^2$, $R^2_{adj}$,
$AIC$, $BIC$ and cross-validation. Let's try comparing models using these
statistics to see how well each statistic captures our intuition about the best
model to use.





$\\$







### Part 2.1: Comparing models with R^2, adjusted R^2, AIC, BIC


Let's compare models using these statistics: 

 * `R^2`: where a higher value means a better fit
 * `Adjusted R^2`: where higher value means a better fit
 * `AIC`: where a lower value means a better model
 * `BIC`: where a lower value means a better model

We can use either the synthetic x, y, data we created above, or the assistant
professor data. We will fit the model with different degree polynomials and wee
which modle each statistic selects.


```{r}


library(dplyr)


# fit models of degree 1, 3, and 5
#fit_1 <- lm(y ~ poly(x, 1, raw=TRUE))
#fit_3 <- lm(y ~ poly(x, 3, raw=TRUE))
#fit_5 <- lm(y ~ poly(x, 5, raw=TRUE))


fit_1 <- lm(salary_tot ~ poly(log(endowment), 1), data = assistant_data)
fit_3 <- lm(salary_tot ~ poly(log(endowment), 3), data = assistant_data)
fit_5 <- lm(salary_tot ~ poly(log(endowment), 5), data = assistant_data)



# summarizing these models
fit1_summary <- summary(fit_1)
fit3_summary <- summary(fit_3)
fit5_summary <- summary(fit_5)



# printing the R^2 values (higher is better)
cat('R^2 \n')
(rsquared_values <- c(fit1_summary$r.squared, fit3_summary$r.squared, fit5_summary$r.squared))
which.max(rsquared_values)


# printing the adjusted R^2 values (higher is better)
cat("\n Adjusted R^2 \n")
(adjusted_rsquared_values <- c(fit1_summary$adj.r.squared, 
                              fit3_summary$adj.r.squared,
                              fit5_summary$adj.r.squared))  
which.max(adjusted_rsquared_values)



# printing the AIC values (lower is better)
cat("\n AIC \n")
(aic_values <- c(AIC(fit_1), AIC(fit_3), AIC(fit_5)))
which.min(aic_values)
  

# printing the BIC values (lower is better)
cat("\n BIC \n")
(bic_values <- c(BIC(fit_1), BIC(fit_3), BIC(fit_5)))
which.min(bic_values)



```





$\\$







### Part 2.2: Comparing models using cross-validation


Let's now compare the models using cross-validation. To keep things simple, we
are just going to split the data once into a training set and a test set rather
than do k-fold cross-validation.

We will compare the models based on their mean squared prediction error (MSPE)
where a smaller MSPE is better.



```{r}


# create the training set and the test set
total_num_points <- dim(assistant_data)[1]
num_training_points <- floor(nrow(assistant_data)/2)

training_data <- assistant_data[1:num_training_points, ]
test_data <- assistant_data[(num_training_points + 1):total_num_points, ]



# fit both models on the training data, and calculate the MSPE based on their predictions on the test set

fit_cv_1 <- lm(salary_tot ~ poly(log(endowment), 3), data = training_data)
test_predictions_1 <- predict(fit_cv_1, newdata = test_data)
MSPE_smaller_model <- mean((test_data$salary_tot - test_predictions_1)^2)
  

fit_cv_2 <- lm(salary_tot ~ poly(log(endowment), 5), data = training_data)
test_predictions_2 <- predict(fit_cv_2, newdata = test_data)
MSPE_larger_model <- mean((test_data$salary_tot - test_predictions_2)^2)
 

MSPE_smaller_model   # smaller MSPE is better
MSPE_larger_model

which.min(c(MSPE_smaller_model, MSPE_larger_model))




# use a for loop to compare the MSPE for models of degree 1 to 7
cv_results <- NULL
for (i in 1:7) {
  curr_fit_cv <- lm(salary_tot ~ poly(log(endowment), i, raw = TRUE), data = training_data)
  curr_test_predictions <- predict(curr_fit_cv, newdata = test_data)
  cv_results[i] <- mean((test_data$salary_tot - curr_test_predictions)^2) 
 }
plot(cv_results, type = "o")


```






$\\$






## Part 3: Visualizing multiple regression models with ggplot

Note: we likely won't get to this in today's class but will go over it in a future class (likely class 22)

In prior classes we have visualized multiple regression models with categorical
predictors using base R graphics. In particular, we created scatter plots for
data in different categories using the `plot()` and `points()` and used the
`col` argument to color the points. We then added on regression lines using the
`abline()` function. This method was useful for educational purposes so that we
could see the connection between the model parameters that were estimated using
the `lm()` function, and the underlying data. However, if we want to create
better looking visualizations in a more efficient manner, then it is better to
use ggplot.

Let's now use ggplot to visualize a multiple regression model that has one
quantitative and one categorical variable. In particular, let's recreate the
plot from class 19 part 3.6 where we display faculty salaries as a function of
log endowment separately for different faculty ranks.


**NOTE: You are not allowed to use ggplot to plot model fits on homework 8, but instead you need to use base R graphics**



```{r}

library(ggplot2)

# create the IPED data subset used in class 19 part 3
IPED_2 <- IPED_salaries |>
filter(endowment > 0) |>
mutate(log_endowment = log10(endowment)) |>
filter(CARNEGIE %in% c(15, 31)) |>
filter(rank_name %in% c("Assistant", "Associate", "Full"))
dim(IPED_2)



# using ggplot
IPED_2 |>
  ggplot(aes(log_endowment, salary_tot, col = rank_name)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  xlab("Log endowment") + 
  ylab("Salary ($)")



```

