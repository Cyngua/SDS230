---
title: "Homework 4"
output:
  pdf_document: default
  html_document:
    df_print: paged
---




$\\$




The purpose of this homework is to gain a better understanding of how to run parametric hypothesis tests and to see the connections between different types of hypothesis tests. Please fill in the appropriate code and write answers to all questions in the answer sections, then submit a compiled pdf with your answers through Gradescope by 11pm on Sunday October 3rd. 

As always, if you need help with the homework, please attend the TA office hours which are listed on Canvas and/or ask questions on [Ed Discussions](https://edstem.org/us/courses/12764/discussion/). Also, if you have completed the homework, please help others out by answering questions on Ed Discussions which will count toward your class participation grade. Finally, be sure to "show your work" by printing out any numbers relevant to your answers in the R code chunks. 




<!--  Please run the code in the  R chunk below once. This will install some packages and download data and images needed for these exercises.  -->

```{r message=FALSE, warning = FALSE, echo = FALSE, eval = FALSE}

SDS230::download_data("freshman-15.txt")
SDS230::download_image("covid19.png")
SDS230::download_image("math_law.png")

```




<!-- The R chunk below sets some parameters that will be used in the rest of the document. Please ignore it and do not modify it. -->
```{r message=FALSE, warning=FALSE, tidy=TRUE, echo = FALSE}

library(knitr)
library(latex2exp)
library(dplyr)

options(scipen=999)

opts_chunk$set(tidy.opts=list(width.cutoff=60)) 
set.seed(230)  # set the random number generator to always give the same random numbers
    
```






$\\$





## Part 1: Sinister lawyers revisited  


On homework 3 you investigated whether lawyers are more sinister than the typical US adults using a permutation test and the bootstrap. Let's try running these analyses again using parametric methods!

As you will recall from homework 3, it is known that 10% of US adults are left-handed (i.e., are sinister). A study took a random sample of 105 lawyers and found that 16 were left-handed. Does this provide evidence that a higher proportion of lawyers are left-handed compared to the US population?  Please complete the 5 steps of hypothesis testing **using parametric hypothesis tests** as described below to reexamine this question.



$\\$






**Part 1.1 (2 points)**: When running a hypothesis test we should start with step 1 by stating the null and alternative hypotheses. Please state these hypotheses again, in (LaTeX) symbols and words, for testing whether a higher percentage of lawyers are left-handed compared to the general US population. 



**Answer**: 







$\\$






**Part 1.2 (2 points) **: Now do step 2 of hypothesis testing by computing the statistic of interest. For the sake of making it easier to work with the binomial distribution, let's have our statistic be the actual number of left-handed lawyers rather than the proportion of left-handed lawyers, so save this number to an object called `lawyer_stat`. 


```{r part_1_2}
  


  
```








$\\$






**Part 1.3 (6 points) **: On homework 3 you used the `rbinom()` function to create an approximate null distribution. For this analysis, instead of randomly generating data using a binomial distribution, let's use the actual binomial probability distribution. 

To start this analysis, let's visualize a binomial null distribution by plotting the appropriate binomial "density" function; (as briefly mentioned in class, since the binomial distribution is a discrete distribution, technically you are plotting the binomial "mass" function rather than a density function, but they serve the same purpose). 

Please create the plot of the binomial mass function that would be the appropriate null distribution for this study. To create this plot, please do the following:

- Use the `plot(x, y, type = "h")` function to create the plot, where the values on the x-axis should be successive integers representing "the number of left-handed lawyers", and the values in y-axis should be the probability. 

- Make sure the plot covers a range of values around where the probability is above 0 (i.e., don't include a large range of values where the probability is very close to 0).

- As always, make sure the plot is labeled appropriately. Also, experiment with the `lwd` argument to make the bars on the plot a bit thicker. 


Hint: looking at the material from week 3 could be helpful, although use the `plot()` function instead of the `barplot()` function.



```{r part_1_3}









    
```





$\\$





**Part 1.4 (5 points)**: Now use the binomial distribution to get the probability that 16 or more lawyers would be left-handed if the null hypothesis was true. In the answer section below please describe: 

- What would you conclude using a significance level of 0.05? 
- Is the p-value similar to the p-value you got from homework 3 and would you arrive at the same conclusion? 


```{r part_1_4}
    



    
```

**Answer**: 









$\\$








## Part 2: Are sinister lawyers normal? 


As we've seen, we can use "randomly flipping" coins as a model for the null distribution in our lawyer example (homework 3), and that we can use the actual binomial distribution as a null distribution for this problem (part 1 above). Now let's examine if we can also use a normal probability distribution as a null distribution for modeling the number of left-handed lawyers. Let's start by explaining the logic of why this might be a reasonable thing to do.


### Bernoulli, Binomial and Normal distribtuions

One of the simplest probability distributions is called the Bernoulli distribution, which models a single coin flip. In the Bernoulli distribution, the values a random variable X can take on are 0, and 1, where 0 corresponds to getting a "tail" and 1 corresponds to a "head". The Bernoulli distribution has a single parameter $\pi$ which is the probability of getting a 1 (i.e., a head) on a single coin flip. 

One way to think about the binomial distribution is in terms of a sum of outcomes from `n` independent Bernoulli trials. Namely, the binomial distribution models flipping `n` coins where the probability of getting heads (i.e., a 1) on each flip is given by the parameter $\pi$. Thus the binomial distribution is just the sum of `n` independent Bernoulli trials. 

In class we discussed the Central Limit Theorem, which states that when a large number of random outcomes are summed together, the result distribution is a normal distribution. Since the binomial distribution is a sum of Bernoulli random variables, we should expect the binomial distribution to become close to a normal distribution as the sample size `n` increases. Let's explore this more here to see if we can use the normal distribution as a null distribution for our left-handed lawyers. 



**Part 2.1 (5 points)**: 

In part 1a and part 1b above, you already did steps 1 and 2 of hypothesis testing, so we can skip them here. Let's start our hypothesis tests at step 3 where we will assess if a normal distribution could be a reasonable null distribution. 

As you hopefully recall, a normal distribution has two parameters $\mu$ and $\sigma$. Using calculations from probability, one can show that if one wanted to use a normal distribution to model a binomial random variable, the parameter values for the normal distribution should be:

- $\mu = n \cdot \pi$
- $\sigma = \sqrt{n \cdot \pi \cdot (1 - \pi)}$


Using the value for $\pi$ specified by the null hypothesis, calculate what the values for $\mu$ and $\sigma$ should be when using a normal probability model as the null distribution, and save these values to objects called `mu` and `sigma`. 


```{r part_2_1}





```






$\\$





**Part 2.2 (10 points)**: 

Now that you've calculated the parameters for using a normal distribution as a null distribution, let's compare this normal null distribution to the binomial distribution you created in part 1.3 by doing the following steps:

1. Replot the binomial null distribution from part 1.3 above

2. Create a normal density curve using the $\mu$ and $\sigma$ parameters calculated in part 2.1. Be sure to use the same x-values when creating this density curve that you used in your plot of the binomial distribution.

3. Use the `points()` function to plot the normal density curve on top of the binomial curve. Make the normal density curve blue and use the `type = "o"` argument to plot both a connected line as well as circles at each value.  Note, the `points()` function works exactly the same as the `plot()` function except that it adds the new plot on top of what has already been plotted; (also, you need to run both lines in sequence to have plot one on top of the other).

In the answer section below, describe if the normal distribution seems like a reasonable approximation to the binomial distribution.


```{r part_2_2}











```

**Answer**: 






$\\$





**Part 2.3 (5 points)**: 

Now use a normal distribution with the parameters calculated above to get the p-value. Is the p-value that you get from using a normal distribution close to the p-value you got from using the binomial distribution? Would you arrive at the same conclusions? 



```{r part_2_3}




```

**Answers**: 






$\\$




![](math_law.png)





$\\$






## Part 3: Analyzing data using t-tests


The term "Freshman 15" refers to the belief that college students frequently gain weight during their freshman year (i.e., it is believed that students gain 15 lbs). To test whether students do in fact gain weight during their first year at college, David Levitsky, a Professor of Nutrition at Cornell College, recruited students from an introductory health course. The students were weighed during the first week of the semester, then again 12 weeks later. 

The data from 68 students in Professor Levitskyâ€™s class is loaded below and contains the following variables:

- `Subject`: An ID number for each participant who volunteered their weight.
- `Initial.Weight`: The weight of each participant at the start of the semester.
- `Terminal.Weight` The weight of each participant at the end of the semester.

Let's run a few t-tests to see if students do indeed gain weight (on average) over the course of the semester. 



```{r part_3_0}

freshman <- read.table("freshman-15.txt", header = TRUE)

```




$\\$




**Part 3.1 (5 points)**: 

Let's start by running an "independent samples" t-test where we treat the initial weight and final weight as independent samples (i.e., for practice running t-tests, we will treat the initial and final measurements as if they came from different people). Please start with step 1 by stating the null and alternative hypothesis in words and using our commonly used symbols. 


**Answer**






$\\$




**Part 3.2 (8 points)**: 

Now let's visualize the data and calculate the statistic of interest. Please use an appropriate plot to compare the students' weights at the start and end of the semester. Also calculate and store the value of the statistic in an object called `t_stat`, and report its value. Recall for Welch's t-test, the t-statistic is defined as: 

$t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s^2_1}{n1} + \frac{s^2_2}{n2}}}$

where:

 - $\bar{x}_1$ and $\bar{x}_2$ are the means of the two groups.
 - $s^2_1$ and $s^2_2$ are the variances of the two groups.
 - $n_1$ and $n_2$ are the samples sizes of the two groups.


Based on the plot, does it seem that students gain weight? 


Note: if you have trouble reading the above equation, please knit this document to a pdf, and you should then be able to zoom in on the equation (and also see the class slides). 


```{r part_3_2}












```


**Answer** 






$\\$






**Part 3.3 (8 points)**: 

To run Welch's t-test, the following conditions need to be met:  

1. The data come from normal populations, or, as a rule of thumb, the sample sizes for the two groups are greater than 30. 

2. Like all hypothesis tests we run, we assume that data points within each group are independent (we will ignore any dependence between the two samples for this analysis). 


If these conditions are met, the t-statistic should come from a null t-distribution with (conservative) degrees of freedom of the minimum of $n_1$ - 1 and $n_2$ - 1. 

Please plot this null t-distribution below, and draw a red line at the observed t-statistic value you calculated in part 3.2. Based on the plot you created, does it appear that the results will be statistically significant? 

```{r part_3_3}












```

**Answer** 






$\\$







**Part 3.4 (5 points)**: 

Now calculate the p-value (hypothesis test step 4). Report below whether the results are statistically significant (hypothesis tests step 5). Also report what you would conclude. 


```{r part_3_4}





```

**Answer**








$\\$






**Part 3.5 (5 points)**: 

R has a built in function to do a t-test called `t.test(sample1, sample2)`. Please print out the results from running this function and report: 

1. Do you get the same t-statistic value as you computed above in part 3.2?
2. Do you get the same p-value as you computed above in part 3.4? 
3. If you get any different results, what could be causing the difference? 



```{r part_3_5}





```

**Answer**

1.
2. 
3. 





$\\$





**Part 3.6 Challenge question (10 points)**: 

**This is a "challenge problem" that you should try to figure out without getting help from the TAs. Challenges problems might be more difficult than other problems but they won't be worth too many points, so they will not have a large impact on your homework score.**


As you likely observed, the data collected here is based on repeated measures of the same participants. We can leverage this fact to run a paired samples t-test which is much more powerful (i.e., it has a much higher ability to reject the null hypothesis when it is false). The reason the paired samples t-test is so much more powerful is because there is a lot of variability between different people in the study, so if we can factor that out and only focus on the weight gained by each person, we will have a much better chance of rejecting the null hypothesis if it is false. 

The paired samples t-test assesses whether the difference between two measurements on the same observational units is 0 on average (it can also be used to test if the difference is another value apart from 0, but that is less common). To run this test, we first calculate the difference score for each participant between the two measurements. We then calculate the follow t-statistic:

$t = \frac{\bar{x}_d}{\frac{s_d}{\sqrt{n}}}$  

where:
- $\bar{x}_d$ is the mean of the difference scores 
- $s_d$ is the standard deviation of the difference scores 
- $n$ is the number of samples (where each sample is consists of two values)

Provided that the difference scores are approximately normal (or n is large), and that, as always, the data points are independent, then the t-statistic should come from a t-distribution with n - 1 degrees of freedom. 


Please run the 5 hypothesis steps to run a paired t-test on the freshman 15 data. In particular, please do the following:

1. State the null and alternative hypothesis using the appropriate symbols.
2. Create an appropriate plot of the data and calculate the statistic of interest. 
3. Plot the null distribution with the observed statistic as a red line.
4. Calculate the p-value.
5. Report the conclusions. 



$\\$



**Step 1:**









$\\$




**Step 2:**

```{r part_3_6_2}








```


$\\$




**Step 3:**


```{r part_3_6_3}






```


$\\$



**Step 4:**


```{r part_3_6_4}






```


$\\$



**Step 5:**










$\\$


I am not sure about the freshman 15, but having spent the past year largely inside, it is clear that the covid-19 is real.


![](covid19.png)




$\\$





## Part 4: Assessing the t-tests type I error rate


As discussed in class, if the Neyman-Pearson paradigm was followed perfectly, we would expect that only $\alpha$ proportion of hypothesis tests that were run would result in type I errors. We can use this fact to evaluate whether a given type of hypothesis test is "robust" to violations of the assumptions/conditions that are supposedly required to use a method. 

In particular, we can use simulated data, where we know what the parameters values are, to assess whether a particular type of hypothesis test produces type I errors at the rate that is expected. We can do this by repeatedly generating random data, and then calculating the p-values from these samples. Once we have a large collection of p-values, we can assess the whether proportion of times that the test rejects the null hypothesis matches the specified significance level $\alpha$. If it matches, then the method is working properly, otherwise, it is not reliable. Let's briefly explore this below by assessing how robust the independent sample t-test is to violations of the condition that the data in each sample comes from a normal distribution. 



$\\$




**Part 4.1 (3 points)**: 

To make our lives easier, we will follow our analysis in part 3.5 above, and use the `t.test()` function to get p-values. When we run the `t.test()` function, the returned result is a data structure that contains many values related to the t-test (i.e., the object that is returned from running the t.test function is an object similar to a list and it contains the t-statistic, the degrees of freedom, the p-value, etc.). If we assign the output of running the `t.test()` function to an object called `result`, we can use the syntax `result$p.value` to get the p-value from running the hypothesis test. 

Please use the `t.test()` function to once again run an independent samples t-test between the initial and final weights for the 68 freshman. Then extract the p-value and save it to an object called `pval`. Finally, print what is stored in your `pval` object to show you have extracted the correct p-value. 

```{r part_4_1}






```




$\\$




**Part 4.2 (10 points)**: 

One condition for running an independent samples t-test is that the data from the samples come from normal distributions. Let's start by assessing the type I error rate that occurs when this assumption is met. To do this we can create a for loop where continually add results to a vector called `rejections`. In each iteration of the for loop we will: 

1. Create a first sample of 10 random values from a standard normal distribution and save this data to an object called `sample_1`.
2. Create a second sample of 10 random values from a standard normal distribution and save this data to an object called `sample_2`.
3. Use the `t.test()` method to get a p-value from running an independent samples t-test between `sample_1` and `sample_2`.
4. Assess whether the p-value is less than a specified $alpha = 0.05$ level and store the resulting Boolean in our `rejection` object; i.e., a value of `TRUE` means the null hypothesis was rejected and a value of `FALSE` means it was not.

Once we have run the for loop for 10,000 iterations, we can assess the proportion of rejections and see whether it matches our $\alpha = 0.05$ level. 

Please run the analysis below. Report the proportion of null hypotheses that were rejected and consequently if it appears that t-test is indeed giving the expected type I error rate.


```{r part_4_2}











```

**Answer** 






$\\$




**Part 4.3 (8 points)**: 

Above we assessed with ideal conditions where the data comes from normal distributions. A more interesting question is what happens when some of the assumptions of the t-test are violated. Let's explore this by recreating the code above, but rather than sampling 10 points for each sample from a normal distribution, instead sample the points from a standard exponential distribution (i.e., an exponential distribution with a rate parameter of 1), which is a distribution that has long tails. 

Please estimate and report the type I error rate using the code chunk below, and answer whether the t-test appear to be robust to the assumption that the data comes from normal distributions. 



```{r part_4_3}












```

**Answer**  







Note: this simulation approach can be used to assess the robustness of many properties and methods including how outliers impact particular methods, and also to assess whether confidence intervals are capturing the parameters the correct proportion of the time (e.g., this methods could be used to assess whether bootstrap confidence intervals are working correctly, etc.). 




## Reflection (3 points)



Please reflect on how the homework went by going to Canvas, going to the Quizzes link, and clicking on [Reflection on homework 4](https://yale.instructure.com/courses/68751/quizzes/40871)





